{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About me Thiago is a dad, financial economist, and software engineer. Contact \ud83c\udfa3 \ud83e\udd8a GitHub: tsilva \ud83c\udf10 Website: tsilva.github.io \ud83d\udc54 LinkedIn: Thiago Silva \ud83d\udcec Email: tasilva96@gmail.com","title":"About"},{"location":"#about-me","text":"Thiago is a dad, financial economist, and software engineer.","title":"About me"},{"location":"#contact-","text":"\ud83e\udd8a GitHub: tsilva \ud83c\udf10 Website: tsilva.github.io \ud83d\udc54 LinkedIn: Thiago Silva \ud83d\udcec Email: tasilva96@gmail.com","title":"Contact \ud83c\udfa3"},{"location":"stuff/","text":"Welcome to Talon Hight-Performance Computing Documentation BTW this is mobile friendly and easy to deploy on GitHub Pages http://UNT-RITS.github.io/talon_sop/_build/html/index.html Task List Lorem ipsum dolor sit amet, consectetur adipiscing elit Nulla lobortis egestas semper Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Sed egestas felis quis elit dapibus, ac aliquet turpis mattis Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Bundle code together Bash #!/bin/bash echo \"Hello world!\" C #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } C# using System ; class Program { static void Main ( string [] args ) { Console . WriteLine ( \"Hello world!\" ); } } Python Starter Content import tensorflow as tf import os print ( \"Hello world\" ) import tensorflow as tf import os print ( \"Hello world\" ) Formulas \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \u2013 we can use Material Design icons :fontawesome-regular-laugh-wink: \u2013 we can also use FontAwesome icons :octicons-octoface: \u2013 that's not all, we can also use GitHub's Octicons Foot Note Lorem ipsum 1 dolor sit amet R Starter Content Job Submit Content Tables Fruit List Apple Banana Kiwi Fruit Table Fruit Color Apple Red Banana Yellow Kiwi Green Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"Welcome to Talon Hight-Performance Computing Documentation"},{"location":"stuff/#welcome-to-talon-hight-performance-computing-documentation","text":"BTW this is mobile friendly and easy to deploy on GitHub Pages http://UNT-RITS.github.io/talon_sop/_build/html/index.html","title":"Welcome to Talon Hight-Performance Computing Documentation"},{"location":"stuff/#task-list","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit Nulla lobortis egestas semper Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Sed egestas felis quis elit dapibus, ac aliquet turpis mattis Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Nulla vel eros venenatis, imperdiet enim id, faucibus nisi","title":"Task List"},{"location":"stuff/#bundle-code-together","text":"Bash #!/bin/bash echo \"Hello world!\" C #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } C# using System ; class Program { static void Main ( string [] args ) { Console . WriteLine ( \"Hello world!\" ); } }","title":"Bundle code together"},{"location":"stuff/#python-starter","text":"","title":"Python Starter"},{"location":"stuff/#content","text":"import tensorflow as tf import os print ( \"Hello world\" ) import tensorflow as tf import os print ( \"Hello world\" )","title":"Content"},{"location":"stuff/#formulas","text":"\\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \u2013 we can use Material Design icons :fontawesome-regular-laugh-wink: \u2013 we can also use FontAwesome icons :octicons-octoface: \u2013 that's not all, we can also use GitHub's Octicons","title":"Formulas"},{"location":"stuff/#foot-note","text":"Lorem ipsum 1 dolor sit amet","title":"Foot Note"},{"location":"stuff/#r-starter","text":"","title":"R Starter"},{"location":"stuff/#content_1","text":"","title":"Content"},{"location":"stuff/#job-submit","text":"","title":"Job Submit"},{"location":"stuff/#content_2","text":"","title":"Content"},{"location":"stuff/#tables","text":"Fruit List Apple Banana Kiwi Fruit Table Fruit Color Apple Red Banana Yellow Kiwi Green Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"Tables"},{"location":"activities/activities/","text":"Activities Discuss about NLP & Hugging Face Library Slides august 13, 2021 | Plano, TX Thiago","title":"Activities"},{"location":"activities/activities/#activities","text":"","title":"Activities"},{"location":"activities/activities/#discuss-about-nlp--hugging-face-library","text":"Slides august 13, 2021 | Plano, TX Thiago","title":"Discuss about NLP &amp; Hugging Face Library"},{"location":"resume/resume/","text":"Resume pdf Summary How I got here? Neural networks are the reason I started my PhD in computer science. The professor I talked asked me if I wanted to work on natural language processing and neural network. The notion of neural networks sounded very exciting to me. That\u2019s when I knew that is what I want to do for my career. Interest areas: Neural Networks , Deep Learning , Natural Language Processing , Reinforcement Learning , Computer Vision , Scaling Machine Learning . Research: My main research area is in NLP with focus on dialogue generation with persona. I use the Friends TV corpus to train language models that can capture each of the main six characters personas. Imagine a chatbot that sounds like Joey or Chandler. This will make chatbots systems more engaging and allow shifting personas depending on a customer's mood which significantly increases customer experience. In my free time: I like to share my knowledge on NLP: I write tutorials from scratch on state-of-the-art language models like Bert and GPT2 with over 10k views. Check them out here . Contribute to open-source software on GitHub \u2013 Hugging Face Transformer and Dataset library. Technical reviewer for one of the first books published on transformers models for NLP. The book is called Transformers for NLP in Python, by Denis Rothman. Most recently I was invited to be a technical reviewer for the next edition of the Transforms for NLP book. I delivered a webinar on my tutorial GPT2 for Text Classification with 300+ participants and 50 of them requested me to publish more on this topic. Experience Data Scientist, Part-Time TCF Bank \u2013 Huntington Bank | Machine Learning Operations Translated credit risk models into python and R with unit testing implementation. Built a Proof of Concept (PoC) application around Machine Learning (ML) Operations (MLOps) framework on Kubernetes: automated model registry and deployment using MLFlow, data pipelines with Airflow, API model calls using FastApi and CI/CD pipeline in Jenikins. Helped transition from MLOps solution vendor that reduced model deployment cost to zero. Jan 2021 \u2013 Present Data Scientist Intern State Farm | Enterprise Data & Analytics Created a PoC application for stock portfolio optimization using Reinforcement Learning (RL) in Python. Built a RL framework tool that makes it transferable in different business areas to help create RL environments and models. Helped create a PoC application that optimizes claims automatic payment process using RL in Python. May 2020 \u2013 July 2020 Data Scientist \u2013 Machine Learning Engineer University of North Texas (UNT) | Research Information Technology Helped research labs with model implementations, debugging and attract more funding. Helped maintain latest ML and deep learning frameworks for University of North Texas High Performance Computing (HPC) center. Created and held workshops and tutorials on NLP and using HPC services that helped increased userbase by 20%. Sep 2018 - May 2020 Machine Learning Engineer Intern State Farm | Enterprise Data & Analytics Automated modeling evaluation in python: build baselines and compare against target model reducing deployment timeline by 90%. Wrote and published a python package for automatic model evaluation that can be used across different departments. Built python program to generate HTML reports on baseline model evaluation and data analysis plots integrated in a CI/CD pipeline. May 2019 \u2013 July 2019 Data Scientist Intern State Farm | Enterprise &Data Analytics Introduced GPUs in ML tutorials that speed up training by over 50%. Used Natural Language Processing (NLP) tools in python to extract meaningful features from claims text data that were used in addition to existing claims feature to increase model baseline performance in predicting claims duration. May 2018 \u2013 August 2018 Teaching Assistant \u2013 Computer Science University of North Texas (UNT) | Department of Computer Science Building and debugging C/C++ coding assignments and help coordinate coding exams. \udbff\udc00* Peer mentor and grader for students in Computer Science basic and advance courses. Sep 2017 \u2013 May 2018, Sep 2020 \u2013 May 2021 Artificial Intelligence \u2013 Machine Learning Researcher University of North Texas (UNT) | Department of Computer Science Implement concepts in python from research papers related to NLP and Computer Vision (CV). \udbff\udc00* Building state of the art deep learning models in python in the domains of language modeling and image classification. Jan 2017 - Present Education Doctor of Philosophy (PhD) in Computer Science University of North Texas (UNT) | Department of Computer Science Research Areas: ML, deep learning, NLP, CV. Dec 2021 | GPA 4.0 Master of Computer Science University of North Texas (UNT) | Department of Computer Science Relevant Coursework: Machine Learning, Deep Learning, Big Data, Natural Language Processing, Image Processing. Dec 2019 | GPA 3.9 Skills Proficient: Python, Tensorflow, PyTorch Need Warmup: Java, C, C++, Matlab, R Intermediate: SQL, Docker, AWS, Swift, Android, Hadoop, HTML Reference Dr. Rodney D. Nielsen Associate Professor - Director HiLT Lab University of North Texas \u2013 Computer Science Engineer Email: Rodney.Nielsen@UNT.edu","title":"Resume"},{"location":"resume/resume/#resume--pdf","text":"","title":"Resume  pdf"},{"location":"resume/resume/#summary","text":"How I got here? Neural networks are the reason I started my PhD in computer science. The professor I talked asked me if I wanted to work on natural language processing and neural network. The notion of neural networks sounded very exciting to me. That\u2019s when I knew that is what I want to do for my career. Interest areas: Neural Networks , Deep Learning , Natural Language Processing , Reinforcement Learning , Computer Vision , Scaling Machine Learning . Research: My main research area is in NLP with focus on dialogue generation with persona. I use the Friends TV corpus to train language models that can capture each of the main six characters personas. Imagine a chatbot that sounds like Joey or Chandler. This will make chatbots systems more engaging and allow shifting personas depending on a customer's mood which significantly increases customer experience. In my free time: I like to share my knowledge on NLP: I write tutorials from scratch on state-of-the-art language models like Bert and GPT2 with over 10k views. Check them out here . Contribute to open-source software on GitHub \u2013 Hugging Face Transformer and Dataset library. Technical reviewer for one of the first books published on transformers models for NLP. The book is called Transformers for NLP in Python, by Denis Rothman. Most recently I was invited to be a technical reviewer for the next edition of the Transforms for NLP book. I delivered a webinar on my tutorial GPT2 for Text Classification with 300+ participants and 50 of them requested me to publish more on this topic.","title":"Summary"},{"location":"resume/resume/#experience","text":"","title":"Experience"},{"location":"resume/resume/#data-scientist-part-time","text":"TCF Bank \u2013 Huntington Bank | Machine Learning Operations Translated credit risk models into python and R with unit testing implementation. Built a Proof of Concept (PoC) application around Machine Learning (ML) Operations (MLOps) framework on Kubernetes: automated model registry and deployment using MLFlow, data pipelines with Airflow, API model calls using FastApi and CI/CD pipeline in Jenikins. Helped transition from MLOps solution vendor that reduced model deployment cost to zero. Jan 2021 \u2013 Present","title":"Data Scientist, Part-Time"},{"location":"resume/resume/#data-scientist-intern","text":"State Farm | Enterprise Data & Analytics Created a PoC application for stock portfolio optimization using Reinforcement Learning (RL) in Python. Built a RL framework tool that makes it transferable in different business areas to help create RL environments and models. Helped create a PoC application that optimizes claims automatic payment process using RL in Python. May 2020 \u2013 July 2020","title":"Data Scientist Intern"},{"location":"resume/resume/#data-scientist--machine-learning-engineer","text":"University of North Texas (UNT) | Research Information Technology Helped research labs with model implementations, debugging and attract more funding. Helped maintain latest ML and deep learning frameworks for University of North Texas High Performance Computing (HPC) center. Created and held workshops and tutorials on NLP and using HPC services that helped increased userbase by 20%. Sep 2018 - May 2020","title":"Data Scientist \u2013 Machine Learning Engineer"},{"location":"resume/resume/#machine-learning-engineer-intern","text":"State Farm | Enterprise Data & Analytics Automated modeling evaluation in python: build baselines and compare against target model reducing deployment timeline by 90%. Wrote and published a python package for automatic model evaluation that can be used across different departments. Built python program to generate HTML reports on baseline model evaluation and data analysis plots integrated in a CI/CD pipeline. May 2019 \u2013 July 2019","title":"Machine Learning Engineer Intern"},{"location":"resume/resume/#data-scientist-intern_1","text":"State Farm | Enterprise &Data Analytics Introduced GPUs in ML tutorials that speed up training by over 50%. Used Natural Language Processing (NLP) tools in python to extract meaningful features from claims text data that were used in addition to existing claims feature to increase model baseline performance in predicting claims duration. May 2018 \u2013 August 2018","title":"Data Scientist Intern"},{"location":"resume/resume/#teaching-assistant--computer-science","text":"University of North Texas (UNT) | Department of Computer Science Building and debugging C/C++ coding assignments and help coordinate coding exams. \udbff\udc00* Peer mentor and grader for students in Computer Science basic and advance courses. Sep 2017 \u2013 May 2018, Sep 2020 \u2013 May 2021","title":"Teaching Assistant \u2013 Computer Science"},{"location":"resume/resume/#artificial-intelligence--machine-learning-researcher","text":"University of North Texas (UNT) | Department of Computer Science Implement concepts in python from research papers related to NLP and Computer Vision (CV). \udbff\udc00* Building state of the art deep learning models in python in the domains of language modeling and image classification. Jan 2017 - Present","title":"Artificial Intelligence \u2013 Machine Learning Researcher"},{"location":"resume/resume/#education","text":"","title":"Education"},{"location":"resume/resume/#doctor-of-philosophy-phd-in-computer-science","text":"University of North Texas (UNT) | Department of Computer Science Research Areas: ML, deep learning, NLP, CV. Dec 2021 | GPA 4.0","title":"Doctor of Philosophy (PhD) in Computer Science"},{"location":"resume/resume/#master-of-computer-science","text":"University of North Texas (UNT) | Department of Computer Science Relevant Coursework: Machine Learning, Deep Learning, Big Data, Natural Language Processing, Image Processing. Dec 2019 | GPA 3.9","title":"Master of Computer Science"},{"location":"resume/resume/#skills","text":"Proficient: Python, Tensorflow, PyTorch Need Warmup: Java, C, C++, Matlab, R Intermediate: SQL, Docker, AWS, Swift, Android, Hadoop, HTML","title":"Skills"},{"location":"resume/resume/#reference","text":"","title":"Reference"},{"location":"resume/resume/#dr-rodney-d-nielsen","text":"Associate Professor - Director HiLT Lab University of North Texas \u2013 Computer Science Engineer Email: Rodney.Nielsen@UNT.edu","title":"Dr. Rodney D. Nielsen"},{"location":"tutorial_notebooks/test/","text":"Test This is a test","title":"Bert Inner Workings"},{"location":"tutorial_notebooks/test/#test","text":"This is a test","title":"Test"},{"location":"tutorial_notebooks/tutorial_template_page/","text":"Title Work in progress Info Intro to this tutorial What should I know for this notebook? Any requirements. How to use this notebook? Instructions. What ? Tutorial specific answer. Dataset I will use the well known movies reviews positive - negative labeled Large Movie Review Dataset . The description provided on the Stanford website: This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details. Why this dataset? I believe is an easy to understand and use dataset for classification. I think sentiment data is always fun to work with. Coding Now let's do some coding! We will go through each coding cell in the notebook and describe what it does, what's the code, and when is relevant - show the output I made this format to be easy to follow if you decide to run each code cell in your own python notebook. When I learn from a tutorial I always try to replicate the results. I believe it's easy to follow along if you have the code next to the explanations. Downloads Download the Large Movie Review Dataset and unzip it locally. Code Cell: # download the dataset !wget -q -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz # unzip it !tar -zxf /content/aclImdb_v1.tar.gz Installs transformers library needs to be installed to use all the awesome code from Hugging Face. To get the latest version I will install it straight from GitHub. ml_things library used for various machine learning related tasks. I created this library to reduce the amount of code I need to write for each machine learning project. Give it a try! Code Cell: # Install transformers library. !pip install -q git+https://github.com/huggingface/transformers.git # Install helper functions. !pip install -q git+https://github.com/tsilva/ml_things.git Output: Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... done | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 2 .9MB 6 .7MB/s | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 890kB 48 .9MB/s | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1 .1MB 49 .0MB/s Building wheel for transformers ( PEP 517 ) ... done Building wheel for sacremoses ( setup.py ) ... done | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 71kB 5 .2MB/s Building wheel for ml-things ( setup.py ) ... done Building wheel for ftfy ( setup.py ) ... done Imports Import all needed libraries for this notebook. Declare parameters used for this notebook: * * Code Cell: Helper Functions Class() / function() Class / function description. Code Cell: Load Model and Tokenizer Loading the three essential parts of the pretrained transformers: configuration , tokenizer and model . I also need to load the model on the device I'm planning to use (GPU / CPU). Code Cell: Output: Dataset and DataLoader Details. Code Cell: Output: Train Code Cell: Output: Use ColabImage plots straight in here Evaluate Evaluation! Code Cell: Output: Use ColabImage plots straight in here Final Note If you made it this far Congrats and Thank you for your interest in my tutorial! Other details. If you see something wrong please let me know by opening an issue on my ml_things GitHub repository! A lot of tutorials out there are mostly a one-time thing and are not being maintained. I plan on keeping my tutorials up to date as much as I can. Contact GitHub: tsilva Website: tsilva.github.io LinkedIn: silvaThiago Email: Thiagosilva@my.unt.edu.com Schedule meeting: calendly.com/Thiagosilva Thank you! Find out more About Me .","title":"**:gear: Title**"},{"location":"tutorial_notebooks/tutorial_template_page/#title","text":"","title":"Title"},{"location":"tutorial_notebooks/tutorial_template_page/#work-in-progress","text":"","title":"Work in progress"},{"location":"tutorial_notebooks/tutorial_template_page/#info","text":"Intro to this tutorial","title":"Info"},{"location":"tutorial_notebooks/tutorial_template_page/#what-should-i-know-for-this-notebook","text":"Any requirements.","title":"What should I know for this notebook?"},{"location":"tutorial_notebooks/tutorial_template_page/#how-to-use-this-notebook","text":"Instructions.","title":"How to use this notebook?"},{"location":"tutorial_notebooks/tutorial_template_page/#what-","text":"Tutorial specific answer.","title":"What ?"},{"location":"tutorial_notebooks/tutorial_template_page/#dataset","text":"I will use the well known movies reviews positive - negative labeled Large Movie Review Dataset . The description provided on the Stanford website: This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details. Why this dataset? I believe is an easy to understand and use dataset for classification. I think sentiment data is always fun to work with.","title":"Dataset"},{"location":"tutorial_notebooks/tutorial_template_page/#coding","text":"Now let's do some coding! We will go through each coding cell in the notebook and describe what it does, what's the code, and when is relevant - show the output I made this format to be easy to follow if you decide to run each code cell in your own python notebook. When I learn from a tutorial I always try to replicate the results. I believe it's easy to follow along if you have the code next to the explanations.","title":"Coding"},{"location":"tutorial_notebooks/tutorial_template_page/#downloads","text":"Download the Large Movie Review Dataset and unzip it locally. Code Cell: # download the dataset !wget -q -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz # unzip it !tar -zxf /content/aclImdb_v1.tar.gz","title":"Downloads"},{"location":"tutorial_notebooks/tutorial_template_page/#installs","text":"transformers library needs to be installed to use all the awesome code from Hugging Face. To get the latest version I will install it straight from GitHub. ml_things library used for various machine learning related tasks. I created this library to reduce the amount of code I need to write for each machine learning project. Give it a try! Code Cell: # Install transformers library. !pip install -q git+https://github.com/huggingface/transformers.git # Install helper functions. !pip install -q git+https://github.com/tsilva/ml_things.git Output: Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... done | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 2 .9MB 6 .7MB/s | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 890kB 48 .9MB/s | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1 .1MB 49 .0MB/s Building wheel for transformers ( PEP 517 ) ... done Building wheel for sacremoses ( setup.py ) ... done | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 71kB 5 .2MB/s Building wheel for ml-things ( setup.py ) ... done Building wheel for ftfy ( setup.py ) ... done","title":"Installs"},{"location":"tutorial_notebooks/tutorial_template_page/#imports","text":"Import all needed libraries for this notebook. Declare parameters used for this notebook: * * Code Cell:","title":"Imports"},{"location":"tutorial_notebooks/tutorial_template_page/#helper-functions","text":"Class() / function() Class / function description. Code Cell:","title":"Helper Functions"},{"location":"tutorial_notebooks/tutorial_template_page/#load-model-and-tokenizer","text":"Loading the three essential parts of the pretrained transformers: configuration , tokenizer and model . I also need to load the model on the device I'm planning to use (GPU / CPU). Code Cell: Output:","title":"Load Model and Tokenizer"},{"location":"tutorial_notebooks/tutorial_template_page/#dataset-and-dataloader","text":"Details. Code Cell: Output:","title":"Dataset and DataLoader"},{"location":"tutorial_notebooks/tutorial_template_page/#train","text":"Code Cell: Output: Use ColabImage plots straight in here","title":"Train"},{"location":"tutorial_notebooks/tutorial_template_page/#evaluate","text":"Evaluation! Code Cell: Output: Use ColabImage plots straight in here","title":"Evaluate"},{"location":"tutorial_notebooks/tutorial_template_page/#final-note","text":"If you made it this far Congrats and Thank you for your interest in my tutorial! Other details. If you see something wrong please let me know by opening an issue on my ml_things GitHub repository! A lot of tutorials out there are mostly a one-time thing and are not being maintained. I plan on keeping my tutorials up to date as much as I can.","title":"Final Note"},{"location":"tutorial_notebooks/tutorial_template_page/#contact","text":"GitHub: tsilva Website: tsilva.github.io LinkedIn: silvaThiago Email: Thiagosilva@my.unt.edu.com Schedule meeting: calendly.com/Thiagosilva Thank you! Find out more About Me .","title":"Contact"},{"location":"useful/useful/","text":"Code Here is where I put Python code snippets t","title":"Useful Code"},{"location":"useful/useful/#code","text":"Here is where I put Python code snippets t","title":"Code"}]}